Found that

> Think about the type of search you're going to make often in your app.
Then decide on the type of index and whether to create it or not.

> use Explain to understand what algorithms  the optimizer chooses and what arer the slow operations.

> So when you want to make a query faster and you see that its explain plan is lacking index support, think about the query in terms of SLA in your application. Does this query need to run as fast as possible, even when it means that you now have to maintain more indexes?

# Indexes

Last time we saw that filtering on a column with or without an index changes the way the query planner plans and executes the query.

[TODO] show cost difference for same number of rows

Indexes are used to speed up queries by facilitating the filtering part for the planner.
In short, the promess is that a condition over an indexed column is faster than over a non indexed column.
The underlying assumption is that when filtering over an indexed column, that index will always be used. But in reality this is not always the case.

In this session we look at:

- What are indexes ?
- How do indexes work ?
- What are they used for ?
- Any trade-offs when creating indexes ?
- Do they always speed up queries ?
- When to create an index
- What are the different sorts of indexes and when to use them ?
- How to create an index (concurrency) see <https://medium.com/@HereAndBeyond/index-creation-in-postgresql-large-tables-essential-checklist-for-developers-4a344138c0c6>

# What is an index

A data structure is called an index if it is:

- A redundant data structure
- Invisible to the application
- Designed to speed up data selection based on certain criteria

- **redundancy** : redundancy means that an index can be dropped without any data loss and can be reconstructed from data stored elsewhere
- **invisibility** : Invisibility means that an external application using the atabase cannot detect if an index is present or absent. In other words: any query produces the same results with or without an index.
- **performance** : an index is created with the hope that it improves performance of a specific query

In short, the speed-up is achieved due to a fast check of some filtering conditions in a query (WHERE).

An index in a database is like an index in a book.

## Create an index

### UNIQUE and PRIMARY KEYS

In postgreSQL, uniqueness constraints (UNIQUE, PRIMARY KEY) on columns automatically create a unique index.

Without an index, checking uniqueness for primary keys or unique constraints requires a full table scan, which is not efficient for large datasets.
By using an index, PostgreSQL can quickly determine whether a value already exists in the column or not.

By using a UNIQUE index, PostgreSQL determines whether a value already exists in the column or not.

1. **Primary Key**: When you define a primary key on a table, PostgreSQL automatically creates a unique index on the column(s) involved to enforce the uniqueness constraint of the primary key.

2. **Unique Constraints**: Similarly, when you define a `UNIQUE` constraint on one or more columns, PostgreSQL creates a unique index to enforce this constraint, making sure that all values in the column(s) are distinct across the table.

> PostgreSQL doesn't create an index automatically for foreign keys and it's a good practice to manually create one. Without an index, operations like deleting or updating rows on the referenced table can be slow, as PostgreSQL will need to perform a sequential scan to find matching rows. However, the foreign key itself doesn't automatically generate an index.

### Add a UNIQUE constraint on a column and check for the presence of the index

```sql
alter table tree_domains add constraint unique_domain  UNIQUE (domain);
```

Then

```sql
\d tree_domains
```

returns

```sql
Table "public.tree_domains"
 Column |       Type        | Collation | Nullable |                 Default
--------+-------------------+-----------+----------+------------------------------------------
 id     | integer           |           | not null | nextval('tree_domains_id_seq'::regclass)
 domain | character varying |           |          |
Indexes:
    "tree_domains_pkey" PRIMARY KEY, btree (id)
    "unique_domain" UNIQUE CONSTRAINT, btree (domain)
Referenced by:
    TABLE "trees" CONSTRAINT "fk_tree_domain" FOREIGN KEY (domain_id) REFERENCES tree_domains(id)
```

Note the presence of the `unique_domain` UNIQUE CONSTRAINT
Note that both index are `btree`

Now the table has 2 indexes, one for the primary key and one for the UNIQUE domain.

Do the same for other tables.

### Creating an  index

You can create an index on any columns or sets of columns with

```sql
CREATE INDEX index_name ON table USING (column);
```

By default this creates the **B-tree index**, most common index in PostgreSQL.

You can create other types of indexes with ```USING type_of_index```. For instance a `HASH` index:

```sql
CREATE INDEX name ON table USING HASH (column);
```

## B-tree or Balanced-tree index

Let's start with the most common index used in PostgreSQL the
**B-Tree, or balanced tree** and understand how it works.

<https://www.youtube.com/watch?v=NI9wYuVIYcA>

When we do a Sequential Scan we scan all the rows sequentially.

This lookup has a **cost of O(n)** for n rows : the time it takes to look something up doubles when the data doubles.

With a B-tree index, the search has a **cost of O(log(n))**. A doubling of the data implies a factor log_10(2) ~ 1.30 increase in search time.

## Structure - How does a B-tree index work

The B-Tree index has the structure of a ... Tree! but upside down.

The b-tree index organizes the information in hierarchical blocks following an upside down tree.

A B-tree index in PostgreSQL consists of the following key elements: Nodes, Branches and pointers

1. **Root Node**: The topmost node that serves as the entry point for all searches.

2. **Internal Nodes**: Nodes between the root and leaf nodes, used for routing searches by storing pointers and key ranges.

3. **Leaf Nodes**: The bottom-level nodes that store the actual index entries (key-value pairs) and pointers to the corresponding table rows.

4. **Keys**: Ordered values in the nodes used to guide searches, ensuring efficient data retrieval.

5. **Pointers**: Links between nodes (in internal nodes) and to table rows (in leaf nodes) for fast navigation through the index.

![](./../../img/btree-structure.png)

B-tree stores data such that **each node contains keys in ascending order.**

Each of these keys has two references to another two child nodes.

- The left side child node keys are less than the current keys,
- the right side child node keys are more than the current keys

[todo] this is not clear. how does that help with a search ?

A block size is 8 Kb in PostgreSQL.
An 8 Kb block can have dozens of index records.
Consequently, an index with six to seven levels can accomodate billions of index records!

B-trees are very powerful

- huge storage capacity
- super fast retrieval
- limited update impact frm updates, inserts and deletes

## Lifecycle of a B-tree index

### SELECTs

[TODO] walkthrough a search on a column

### Inserts, updates and deletes

Each time a new entry is inserted, rules are applied to keep the index consistent.

- The B-Tree is constructed so that each branch keeps the same depth. No shallow or very deep branches.
- All records in all blocks are ordered
- All blocks have the same size and max number of records
- All blocks are more than half full
- At least 50% of their capacity is utilized.

This reconstruction happens when inserting new data.

So having a B-tree index on a column adds to the INSERT, UDATE and DELETE costs related to that column.

However, B-trees can be modified without significant overhead.

- When a record is inserted, the restructuring is limited to one block.

- If the block capacity is exceeded, then the block is split into two blocks, and the update is propagated to upper levels.

In the worst case, the number of modified blocks cannot exceed the depth of the tree.

## What are B-tree used for ?

In PostgreSQL, a B-tree index can be created for any ordinal data type; that is, for any two distinct values of the data type, one value is less than the other. This includes user-defined types.

However in some cases B-trees are not efficient:

- boolean column : that results in 2 main branches, do no great gain here. b-trees are not adapted to boolean columns
- Very different data like UUIDs or random numbers and many inserts. The B-tree will have to be re-organized often since there is no logic to the values inserted. So also not a good choice
- same thing for `datetime` which is too dynamic

The documentation says:

> B-trees can handle equality and range queries on data that can be sorted into some ordering.
In particular, the PostgreSQL query planner will consider using a B-tree index whenever an indexed column is involved in a comparison using one of these operators:

> <   <=   =   >=   >

> Constructs equivalent to combinations of these operators, such as BETWEEN and IN, can also be implemented with a B-tree index search. Also, an IS NULL or IS NOT NULL condition on an index column can be used with a B-tree index.

So b-trees are efficient when we want to search using a filter on an ordered column, typically a categorical column with many values, orr a numeric colun.

# When to create an index ?

Think about the type of search you're going to make often in your app.
Then decide on the type of index and whether to create it or not.

Then use Explain to understand what algorithms  the optimizer chooses and detect if there are any slow operations.

So when you want to make a query faster and you see that its explain plan is lacking index support, think about the query in terms of SLA in your application.

Does this query need to run as fast as possible, even when it means that you now have to maintain more indexes?

# Demo

We'll use the airdb database,

- EXPLAIN a query on a table without indexes (besides the primary key)
- check out the number of rows and costs returned
- add an index
- verify that the cost has gone down

We'll also add an index on a boolean or date column and see if adding an index impacts the query time and estimated costs.

## B tree recap

[TODO] recap

# Other types of indexes

PostgresQL offers multiple types of indexes (see [documentation chapter 11](https://www.postgresql.org/docs/current/indexes.html)).

- Hash
- GiST and SP-GiST
- GIN
- BRIN

Let's start with HASH Indexes
but first we need to understand the conpect of HASH function

## Hash function

A hash function is a fundamental concept in computer science with wide-ranging applications.

## What is a HASH function?

A hash function is an algorithm that takes
an input (or 'message') of arbitrary size and produces a fixed-size output, typically a string of characters or a number.
This output is called a **hash value**, **hash code**, or simply a **hash**.

![](./../../img/hash-function.png)

The key properties of a good [hash function](https://en.wikipedia.org/wiki/Hash_function) are:

1. **Deterministic**: The same input always produces the same output.
2. **Fast to compute**: It should be quick to calculate the hash for any given input.
3. **Uniform distribution**: The output should be evenly distributed across the possible range of hash values.
4. **Avalanche effect**: A small change in the input should result in a significant change in the output.

Used in many computer science domains including:

1. Data Structures: Hash tables for fast data lookup, insertion, and deletion.
2. Cryptography: Password storage: Securely store passwords by hashing them.
3. Data Integrity: Checksums: Detect accidental changes in data during transmission or storage.
4. Caching: Use hashes as keys to store and retrieve cached data.
5. Blockchain Technology: Proof of work: Fundamental to many cryptocurrency mining algorithms.

Being able to map large and complex data to a simple fixed size string quickly allows for super fast comparisons on all kinds of data.

## Hash indexes

From the documentation:

> Hash indexes store a 32-bit **hash code** derived from the value of the indexed column.
Hence, such indexes can only handle **simple equality** comparisons.
The query planner will consider using a hash index whenever an indexed column is involved in a comparison using ```=```

So what's a hash code and why can't we just use a B-tree index ?

A hash index is a type of database index that uses a hash table data structure to store and retrieve data. It's designed for equality comparisons and can be very efficient for certain types of queries.

Key characteristics of hash indexes:

1. **Structure**: Uses a **hash function** to map column values to hash buckets.
2. **Speed**: Very fast for equality comparisons with **O(1) lookup time** on average.
3. **Size**: Generally smaller than B-tree indexes for large tables.
4. **Operators**: Only equality (=) comparisons.

When to use hash indexes:

1. Equality comparisons: When your queries primarily use equality conditions (e.g., WHERE column = value).
2. Large tables: Hash indexes can be more space-efficient than B-tree indexes for very large tables.
3. High-cardinality columns: Columns with **many unique values** benefit more from hash indexes.
4. Read-heavy workloads: Hash indexes excel in read-intensive scenarios with few updates.
5. Memory-resident tables: Hash indexes perform best when the index can fit entirely in memory.

When not to use hash indexes:

1. Range queries: Hash indexes don't support range-based queries (e.g., WHERE column > value).
2. Sorting: They don't maintain data in sorted order, so they can't be used for ORDER BY operations.
3. Pattern matching: Not suitable for LIKE or regular expression searches.
4. Multi-column indexes: In PostgreSQL, hash indexes can only be created on a single column.
5. Frequently updated columns: Hash indexes may perform poorly if the indexed column is frequently updated.

Example of creating a hash index in PostgreSQL:

```sql
CREATE INDEX idx_user_email ON users USING HASH (email);
```

This would be beneficial for queries like:

```sql
SELECT * FROM users WHERE email = 'user@example.com';
```

It's worth noting that in many cases, especially in PostgreSQL, B-tree indexes are often preferred over hash indexes due to their versatility.
Modern B-tree implementations are highly optimized and can perform nearly as well as hash indexes for equality comparisons while also supporting range queries and sorting.

Before deciding to use a hash index, it's recommended to benchmark your specific use case to ensure it provides a significant performance benefit over a B-tree index.

#### Other examples include

1. Equality queries on large tables:
When you frequently perform exact match queries on a column with many unique values, a HASH index can outperform a B-tree index. For example:

- Table: Users (millions of records)
- Column: email_address (varchar)
- Query: SELECT * FROM Users WHERE email_address = '<user@example.com>';

3. Join operations on unique columns:
When joining tables based on columns with unique values, HASH indexes can speed up the operation:

- Tables: Employees and Departments
- Columns: employee_id (in Employees table), manager_id (in Departments table)
- Query: SELECT * FROM Employees e JOIN Departments d ON e.employee_id = d.manager_id;

It's important to note that HASH indexes are only useful for equality comparisons. They don't support range queries, pattern matching, or ordering operations. In these cases, B-tree indexes would still be preferred.

Also, keep in mind that PostgreSQL's implementation of HASH indexes has improved significantly in recent versions, making them more competitive with B-tree indexes in many scenarios.

Would you like me to elaborate on any of these examples or provide more information about when to choose HASH indexes over B-tree indexes?

### Demo Hash over B-tree ?

## Demo on Hash index

Let's connect to the airdb table on the remote server.
The table booking has over 5m rows

and the following columns

```sql
35.222.95.138 postgres@airdb=# \d booking
                       Table "postgres_air.booking"
    Column    |           Type           | Collation | Nullable | Default
--------------+--------------------------+-----------+----------+---------
 booking_id   | bigint                   |           | not null |
 booking_ref  | text                     |           | not null |
 booking_name | text                     |           |          |
 account_id   | integer                  |           |          |
 email        | text                     |           | not null |
 phone        | text                     |           | not null |
 update_ts    | timestamp with time zone |           |          |
 price        | numeric(7,2)             |           |          |
Indexes:
    "booking_pkey" PRIMARY KEY, btree (booking_id)
    "booking_booking_ref_key" UNIQUE CONSTRAINT, btree (booking_ref)
Foreign-key constraints:
    "booking_account_id_fk" FOREIGN KEY (account_id) REFERENCES account(account_id)
Referenced by:
    TABLE "booking_leg" CONSTRAINT "booking_id_fk" FOREIGN KEY (booking_id) REFERENCES booking(booking_id)
    TABLE "passenger" CONSTRAINT "pass_booking_id_fk" FOREIGN KEY (booking_id) REFERENCES booking(booking_id)
```

Let's pick up a random phone number and compare the query plans before and after crearing a HASH index

Certainly! Let's analyze the differences between these two query plans to understand how the HASH index has improved the query performance.

1. Before creating the HASH index:

# Query Plan Analysis Before HASH Index

- Operation: Gather with Parallel Sequential Scan
- Estimated cost: 1000.00..119071.45
- Actual execution time: 888.074 ms
- Rows returned: 1955
- Workers: 2 planned, 2 launched
- Scan method: Parallel Sequential Scan on the entire booking table
- Filtering: Applied 'phone = '918728050'' condition to each row
- Rows processed: 1,881,072 (1,880,420 removed by filter)
- Additional operations: JIT (Just-In-Time compilation) used

Key points:

1. The database had to scan the entire table (5,643,216 rows across 3 parallel workers).
2. The filter was applied to each row, removing 1,880,420 non-matching rows.
3. The operation was relatively expensive, taking 888.734 ms to execute.

2. After creating the HASH index:

# Query Plan Analysis After HASH Index

- Operation: Bitmap Heap Scan with Bitmap Index Scan
- Estimated cost: 31.42..3555.31
- Actual execution time: 28.618 ms
- Rows returned: 1955
- Scan method: Bitmap Heap Scan using the new HASH index
- Index used: idx_booking_phone_hash
- Heap Blocks accessed: 1943 (exact)

Key points:

1. The database used the HASH index to quickly identify matching rows.
2. A Bitmap Index Scan was performed on the index, followed by a Bitmap Heap Scan to fetch the actual rows.
3. The operation was much faster, taking only 28.892 ms to execute.

Now, let's compare the two plans and explain the key differences:

1. Scan Method:
   - Before: Full table scan (Parallel Sequential Scan)
   - After: Index scan (Bitmap Index Scan followed by Bitmap Heap Scan)

   The HASH index allowed the database to quickly locate the matching rows without scanning the entire table.

2. Execution Time:
   - Before: 888.734 ms
   - After: 28.892 ms

   The query execution time reduced by about 97%, from almost 0.9 seconds to just 0.03 seconds.

3. Rows Processed:
   - Before: 5,643,216 (1,881,072 per worker * 3 workers)
   - After: Only the matching 1,955 rows were processed

   The HASH index eliminated the need to scan and filter out non-matching rows.

4. Cost Estimate:
   - Before: 1000.00..119071.45
   - After: 31.42..3555.31

   The estimated cost decreased significantly, reflecting the expected performance improvement.

5. Operation Complexity:
   - Before: Gather with parallel workers, JIT compilation
   - After: Simple Bitmap scans

   The query plan became simpler and didn't require parallel processing or JIT compilation.

6. Access Method:
   - Before: Sequential scan of all pages
   - After: Direct access to 1943 heap blocks

   The index allowed for targeted access to only the relevant table pages.

In conclusion, the HASH index dramatically improved the query performance by allowing the database to quickly identify and retrieve only the relevant rows, instead of scanning and filtering the entire table. This resulted in a much faster execution time, lower resource usage, and a simpler query plan.

### What about Gather

Excellent question. The GATHER node in the first query plan is a crucial component of parallel query execution in PostgreSQL. Let's dive into what it does and why it's present in the plan without the HASH index.

# PostgreSQL GATHER Node

The GATHER node is a part of PostgreSQL's parallel query execution framework. Its primary functions are:

1. Initiation of parallel workers: It launches a specified number of parallel worker processes.

2. Distribution of work: It divides the work among these parallel workers.

3. Collection of results: It collects the results from all parallel workers.

4. Result ordering: It ensures that the results are returned in the correct order.

Key characteristics:

- Appears in query plans when PostgreSQL decides to use parallel execution.
- Usually sits at or near the top of the execution plan.
- The number of workers is specified in the "Workers Planned" field.
- Can significantly improve performance for large table scans or joins.

Limitations:

- Not all operations can be parallelized.
- The benefit depends on hardware (number of CPU cores) and query characteristics.
- There's some overhead in starting and coordinating parallel workers.

When you see a GATHER node, it indicates that PostgreSQL is attempting to speed up the query by distributing the workload across multiple CPU cores.

Now, let's analyze why the GATHER node is present in the first query plan (without the HASH index) but not in the second one (with the HASH index):

1. In the first query plan (no HASH index):

   ```
   Gather (cost=1000.00..119071.45 rows=957 width=92) (actual time=4.937..888.074 rows=1955 loops=1)
    Workers Planned: 2
    Workers Launched: 2
   -> Parallel Seq Scan on booking (cost=0.00..117975.75 rows=399 width=92)
   ```

   Here, PostgreSQL decided to use parallel query execution. The GATHER node is coordinating two worker processes to perform a Parallel Sequential Scan on the booking table. This decision was made because:

   a) The table is large (over 5 million rows).
   b) Without an index, a full table scan is necessary.
   c) The full table scan is an operation that can benefit from parallelization.

2. In the second query plan (with HASH index):

   ```
   Bitmap Heap Scan on booking (cost=31.42..3555.31 rows=957 width=92)
   -> Bitmap Index Scan on idx_booking_phone_hash (cost=0.00..31.18 rows=957 width=0)
   ```

   Here, there's no GATHER node. PostgreSQL didn't choose to use parallel execution because:

   a) The HASH index allows for efficient direct access to the relevant rows.
   b) The amount of work to be done (scanning the index and fetching specific rows) is much less than a full table scan.
   c) The overhead of starting and coordinating parallel workers would likely outweigh the benefits for this faster operation.

The presence of the GATHER node in the first plan shows that PostgreSQL was trying to optimize the expensive full table scan by parallelizing it. However, once the HASH index was available, the query became so much more efficient that parallelization was no longer beneficial.

This demonstrates how proper indexing can not only speed up queries directly but also simplify query plans by eliminating the need for more complex execution strategies like parallelization.

### B-tree vs HASH

Let's also compare to a B-tree index to see if that's true that B-trees are that efficient.

```sql
CREATE INDEX idx_booking_phone ON booking  (phone);
```

we have a B-tree by default

```sql
Indexes:
    "booking_pkey" PRIMARY KEY, btree (booking_id)
    "booking_booking_ref_key" UNIQUE CONSTRAINT, btree (booking_ref)
    "idx_booking_phone" btree (phone)
```

How does the query fare ?

```sql
 Bitmap Heap Scan on booking  (cost=11.85..3535.74 rows=957 width=92) (actual time=22.175..24.844 rows=1955 loops=1)
   Recheck Cond: (phone = '918728050'::text)
   Heap Blocks: exact=1943
   ->  Bitmap Index Scan on idx_booking_phone  (cost=0.00..11.61 rows=957 width=0) (actual time=21.871..21.872 rows=1955 loops=1)
         Index Cond: (phone = '918728050'::text)
 Planning Time: 3.997 ms
 Execution Time: 24.958 ms
```

-----

# B-tree vs HASH Index Query Plan Comparison

## Key Differences

1. Index Scan Cost:
   - B-tree: 0.00..11.61
   - HASH: 0.00..31.18
   The HASH index has a higher estimated cost for the index scan.

2. Overall Cost:
   - B-tree: 11.85..3535.74
   - HASH: 31.42..3555.31
   The overall estimated cost is slightly higher for the HASH index.

3. Index Scan Time:
   - B-tree: 21.871..21.872 ms
   - HASH: 0.670..0.671 ms
   The HASH index performs the index scan significantly faster.

4. Overall Execution Time:
   - B-tree: 24.958 ms
   - HASH: 28.892 ms
   Despite the faster index scan, the HASH index query has a slightly longer overall execution time.

5. Planning Time:
   - B-tree: 3.997 ms
   - HASH: 6.563 ms
   The query using the HASH index takes longer to plan.
Both plans use a Bitmap Heap Scan with a Bitmap Index Scan, accessing the same number of heap blocks (1943).

#### In conclusion

In conclusion, while the HASH index provides a much faster index scan, this advantage doesn't translate to a faster overall query in this case. The B-tree index performs slightly better overall, possibly due to better optimization in other parts of the query execution or more accurate cost estimation leading to a better overall plan.

This comparison highlights that while HASH indexes can be very fast for equality lookups, they don't always lead to better overall performance. Factors like planning time, accuracy of statistics, and how well the database can optimize the rest of the query execution all play a role. In practice, you'd want to test with your specific data and query patterns to determine which index type performs best for your use case.

-------------

### GiST as in Generalized Search Tree

From the [documentation](https://www.postgresql.org/docs/current/indexes-types.html#INDEXES-TYPE-GIST): GiST indexes are *an infrastructure within which many different indexing strategies can be implemented*.

GiST (Generalized Search Tree) indexes are useful for indexing complex data types and implementing custom indexing methods.
GiST indexes allows us to define how data should be arranged in the index and how searches should be conducted.
GiST can be used for :

1. Geometric data (points, lines, polygons)
2. Full-text search
3. Tree-like structures
4. Range queries

### GiST on POINT data

Let's look at a simple example using geometric data using the trees geolocation column.

Now, let's create a GiST index on the `location` column:

```sql
CREATE INDEX pois_geolocation_idx ON trees USING GIST (geolocation);
```

With this index in place, we can efficiently perform spatial queries, such as finding POIs within a certain distance of a given point:

```sql
SELECT id, geolocation
FROM trees
WHERE location <@ circle '((lat, long), radius)'::circle;
```

### GiST on ARRAY data

Assume you have a product table to store product tags ```TEXT[]```

You can create a GiST index on the tags array

```sql
CREATE INDEX idx_product_tags ON products USING GIST (tags);
```

and query to find products that have **all** specified tags

```sql
SELECT name, tags FROM products WHERE tags @> ARRAY['electronics', 'portable'];
```

or **any** of the specified tags

```sql
SELECT name, tags FROM products WHERE tags && ARRAY['footwear', 'kitchen'];
```

In short use GiST when your query involves these [operators](https://www.postgresql.org/docs/current/functions-geometry.html)

> <<   &<   &>   >>   <<|   &<|   |&>   |>>   @>   <@   ~=   &&

### SP-GiST

An extension of GiST for more exotic data structures, such as quadtrees, k-d trees, and radix trees

### GIN

Also for Arrays but limited to a smaller set of operators:

> @>   <@   =   &&

# Further reading

- The art of postgreSQL Chapter 8 indexing strategy
- PostgreSQL Query Optimization Chapter 5 Short Queries and Indexes

- Hash indexes <https://hakibenita.com/postgresql-hash-index>

<https://www.freecodecamp.org/news/postgresql-indexing-strategies/>

- see also <https://medium.com/@HereAndBeyond/index-creation-in-postgresql-large-tables-essential-checklist-for-developers-4a344138c0c6>
with a good example of creating data with postgresql and using concurrency
